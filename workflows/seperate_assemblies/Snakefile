__author__ = "Johannes Alneberg"
__license__ = "MIT"


import os
import sys
import shutil
import glob
from subprocess import check_output

## Check that no submodule git repo is dirty
#submodules = ["BLUEPRINT_pipeline"]
#for submodule in submodules:
#    submodule_status = check_output(["git", "status", "--porcelain", submodule])
#    if not submodule_status == b"":
#        print(submodule_status)
#        raise Exception("Submodule {} is dirty. Commit changes before proceeding.".format(submodule))
#
## Check that the git repo is not dirty
#submodule_status = check_output(["git", "status", "--porcelain"])
#if not submodule_status == b"":
#    print(submodule_status)
#    raise Exception("Repo is dirty. Commit changes before proceeding.")

configfile: "config.json"

config["fastqc_rules"]["reads"] = {}
config["cutadapt_rules"]["reads"] = {}
if "ray_rules" not in config:
    config["ray_rules"] = {}
    config["ray_rules"]["samples"] = {}
config["megahit_rules"]["samples"] = {}

if os.path.isfile("analysis_per_sample.json"):
    with open("analysis_per_sample.json") as aps:
        analysis_per_sample = json.load(aps)
else:
    analysis_per_sample = {} 


if os.path.isfile("sample_indices.json"):
    with open("sample_indices.json") as aps:
        sample_indices = json.load(aps)
else:
    sample_indices = {"R1_index": {}}

for read_file in glob.glob("samples/raw/*.fq.gz"):
    read_basename = os.path.basename(read_file)
    read_name = read_basename.replace(".fq.gz", "")
    config["fastqc_rules"]["reads"][read_name] = read_file
   
    # Add all steps to fastqc - this will cause fastqc to run after each step 
    # as well as on the raw reads 
    trim_params_name = "quality_adapter_no_indices"
    
    trim_params_dict = config["cutadapt_rules"]["trim_params"][trim_params_name]

    config["fastqc_rules"]["reads"]["cutadapt_"+trim_params_name+"_"+read_name] = \
        "cutadapt/adapt_cutting/{trim_params}/{read}".format(
            trim_params=trim_params_name,
            read = read_basename
        ) 

    config["fastqc_rules"]["reads"]["fastuniq_"+trim_params_name+"_"+read_name] = \
        "fastuniq/{trim_params}/{read}".format(
            trim_params=trim_params_name,
            read = read_basename
        ) 

    # Hack to get read pairs in a list
    read_name = read_name.replace("_R1", "").replace("_R2", "")

    if read_name in config["cutadapt_rules"]["reads"]:
        config["cutadapt_rules"]["reads"][read_name].append(read_file)
        config["cutadapt_rules"]["reads"][read_name].sort()
    else:
        config["cutadapt_rules"]["reads"][read_name] = [read_file]

    # Add the variable barcode sequences for each sample to cutadapt config
    if read_name in analysis_per_sample:
        trim_params_names = analysis_per_sample[read_name]
    else:
        trim_params_names = ["quality_adapter_no_indices"]

    for trim_params_name, trim_params_config in config["cutadapt_rules"]["trim_params"].items():
        if trim_params_name in trim_params_names:
            if "common_variables" in trim_params_config.keys():
                variables = config["cutadapt_rules"]["trim_params"][trim_params_name]["common_variables"].copy()
                if read_name in sample_indices["R1_index"]:
                    variables["R1_index"] = sample_indices["R1_index"][read_name]
                    variables["R2_rev_index"] = sample_indices["R2_rev_index"][read_name]
                if "variables" not in config["cutadapt_rules"]["trim_params"][trim_params_name]:
                    config["cutadapt_rules"]["trim_params"][trim_params_name]["variables"] = {}
                config["cutadapt_rules"]["trim_params"][trim_params_name]["variables"][read_name] = variables

    
config["bowtie2_rules"]["samples"] = {}
config["bowtie2_rules"]["units"] = {}
for read_file in glob.glob("finished_reads/*.fq.gz"):
    read_basename = os.path.basename(read_file)
    read_name = read_basename.replace(".fq.gz", "")
    sample_name = read_name.replace("_R1", "").replace("_R2", "")
    
    if sample_name in config["ray_rules"]["samples"]:
        config["ray_rules"]["samples"][sample_name].append(read_file)
        config["ray_rules"]["samples"][sample_name].sort()
    else:
        config["ray_rules"]["samples"][sample_name] = [read_file]

    if sample_name in config["megahit_rules"]["samples"]:
        config["megahit_rules"]["samples"][sample_name].append(read_file)
        config["megahit_rules"]["samples"][sample_name].sort()
    else:
        config["megahit_rules"]["samples"][sample_name] = [read_file]

    # Add finished_reads for mapping
    read_basename = os.path.basename(read_file)
    read_name = read_basename.replace(".fq.gz", "")
    sample_name = read_name.replace("_R1", "").replace("_R2", "")

    if sample_name in config["bowtie2_rules"]["samples"]:
        config["bowtie2_rules"]["units"][sample_name].append(read_file)
        config["bowtie2_rules"]["units"][sample_name].sort()
    else:
        config["bowtie2_rules"]["units"][sample_name] = [read_file]
        config["bowtie2_rules"]["samples"][sample_name] = [sample_name]

config['concoct_rules']['assemblies'] = {}
for assembly_file in glob.glob("assembly/megahit/*/*/final.contigs.fa*"):
    if not '-slurm.out' in assembly_file:
        assembly_type = assembly_file.split('/')[2]
        sample_name = assembly_file.split('/')[3]
        config['concoct_rules']['assemblies'][assembly_type + '_' + sample_name] = assembly_file

config["assemblies"] = config["concoct_rules"]['assemblies']

#  add 10K cutup as references for bowtie2 to map against
config["bowtie2_rules"].setdefault("references", {}).update({a + "_10K": "binning/concoct/{a}/cutup/contigs_10K.fasta.gz".format(a=a) for a in config["concoct_rules"]["assemblies"]})
config["kallisto_rules"]["references"] = config["bowtie2_rules"]["references"]
config["kallisto_rules"]["samples"] = config["bowtie2_rules"]["units"]

WORKFLOW_DIR = "../../"
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/mapping/samtools.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/mapping/bowtie2.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/quantification/kallisto.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/quantification/khmer.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/quantification/gattaca.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/trimming/cutadapt.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/quality_control/fastqc.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/duplicate_removal/fastuniq.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/assembly/megahit.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/binning/concoct.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/binning/metabat.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/binning/binning_eval.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/annotation/prodigal.rules")
include: os.path.join(WORKFLOW_DIR, "bio/ngs/rules/quality_control/internal_standards.rules")

rule preprocess_all:
    input:
        htmls=expand("fastqc/{reads}/{reads}_fastqc.html", reads=config["fastqc_rules"]["reads"]),
        zips=expand("fastqc/{reads}/{reads}_fastqc.zip", reads=config["fastqc_rules"]["reads"])

